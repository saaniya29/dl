import numpy as np
import matplotlib.pyplot as plt
np.random.seed(42)
X_actual = 2 * np.random.rand(100, 1)
y_actual = 4 + 3 * X_actual + np.random.randn(100, 1)
def gradient_descent(X, y, learning_rate=0.1, n_iterations=1000):
    m = len(y)
    X_b = np.c_[np.ones((m, 1)), X]
    theta = np.random.randn(2, 1)
    for iteration in range(n_iterations):
        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)
        theta -= learning_rate * gradients
    return theta
theta_actual = gradient_descent(X_actual, y_actual)
print("Weights from Actual Data:", theta_actual.ravel())
X_modified = X_actual + np.random.normal(0, 0.1, X_actual.shape)  
y_modified = y_actual + np.random.normal(0, 0.1, y_actual.shape)  
theta_modified = gradient_descent(X_modified, y_modified)
print("Weights from Modified Data:", theta_modified.ravel())
plt.figure()

plt.subplot(1, 2, 1)
plt.scatter(X_actual, y_actual, color='blue', label='Actual Data')
plt.plot(X_actual, X_actual.dot(theta_actual[1:]) + theta_actual[0], color='red')
plt.title('Actual Data')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()

plt.subplot(1, 2, 2)
plt.scatter(X_modified, y_modified, color='green', label='Modified Data')
plt.plot(X_modified, X_modified.dot(theta_modified[1:]) + theta_modified[0], color='red')
plt.title('Modified Data')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.show()
