from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
digits = load_digits()
x = digits.data
y = digits.target
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)
clf1 = RandomForestClassifier(n_estimators=100, random_state=42)
clf1.fit(x_train, y_train)
train_acc1 = accuracy_score(y_train, clf1.predict(x_train))
test_acc1 = accuracy_score(y_test, clf1.predict(x_test))
x_train_small, _, y_train_small, _ = train_test_split(x_train, y_train, test_size=0.75) 
clf2 = RandomForestClassifier(n_estimators=300, random_state=42)
clf2.fit(x_train_small, y_train_small)
train_acc2 = accuracy_score(y_train_small, clf2.predict(x_train_small))
test_acc2 = accuracy_score(y_test, clf2.predict(x_test))
labels = ['Not Overfitting', 'Overfitting']
train_accuracies = [train_acc1, train_acc2]
test_accuracies = [test_acc1, test_acc2]
r = range(len(labels))
plt.bar(r, train_accuracies, label='Training Accuracy', width=0.4, color='blue')
plt.bar([p + 0.4 for p in r], test_accuracies, label='Test Accuracy', width=0.4, color='green')
plt.xlabel(labels)
plt.ylabel('Accuracy')
plt.title('Comparison of Overfitting vs Not Overfitting Models')
plt.show()
